{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keser_Tufan_HW3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_GtTZJpwPGd",
        "outputId": "fba90341-ae4c-4a4b-9573-13001f529919"
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version\n",
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [2 InRelease 0 B/3,626 B 0%] [Wa\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [4 InRelease 14.2 kB/88.7 kB 16%] [Waiting for he\r                                                                               \rGet:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [4 InRelease 14.2 kB/88.7 k\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,748 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,031 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [373 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,400 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [344 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [894 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,168 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,460 kB]\n",
            "Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [49.4 kB]\n",
            "Fetched 11.8 MB in 3s (3,476 kB/s)\n",
            "Reading package lists... Done\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_282\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 71kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 19.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=4d5517154b75256ba4cad8ff6b56879b4875d2f29a01212587a2c7d8080a40ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxZXUvfSK19P",
        "outputId": "4f5fd639-44c1-4595-8ed4-7b64e4f62fcc"
      },
      "source": [
        "pip install quinn   "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting quinn\n",
            "  Downloading https://files.pythonhosted.org/packages/0c/07/22118802e3b19e6afd25d3444704d6e1ba4a1ebf5c336d31cacdf5833a92/quinn-0.9.0-py2.py3-none-any.whl\n",
            "Installing collected packages: quinn\n",
            "Successfully installed quinn-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-Qxg-oJxkCV"
      },
      "source": [
        "from pyspark.sql.functions import UserDefinedFunction\n",
        "from pyspark.sql.types import StringType,IntegerType,DateType,DoubleType\n",
        "from pyspark.sql import SparkSession #DataFrame objeleri yaratmak için gerekli\n",
        "from pyspark.sql.types import StructType,StructField,ArrayType\n",
        "from pyspark.sql.functions import UserDefinedFunction\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml.feature import StringIndexer,VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.tuning import TrainValidationSplit,ParamGridBuilder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import UserDefinedFunction\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml.feature import StringIndexer,VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.tuning import TrainValidationSplit,ParamGridBuilder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import quinn\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "from pyspark.ml.classification import LogisticRegression, OneVsRest\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark import SparkContext"
      ],
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjCc6Y6Sxkox",
        "outputId": "93e06b05-0a5f-4153-957a-fb56951fd7f0"
      },
      "source": [
        "spark = SparkSession.builder\\\n",
        "            .appName(\"Spark Dataframe Intro\")\\\n",
        "            .getOrCreate()\n",
        "            \n",
        "leaf = spark.read\\\n",
        "          .option(\"inferSchema\", \"True\")\\\n",
        "          .option(\"header\", \"true\")\\\n",
        "          .csv(\"leaf.csv\")\n",
        "leaf.printSchema()\n",
        "leaf.createOrReplaceTempView(\"leaf\")\n",
        "leaf = spark.sql(\"select * from leaf\")\n",
        "leaf.take(2)                   "
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- 10: integer (nullable = true)\n",
            " |-- 11: integer (nullable = true)\n",
            " |-- 0.72694: double (nullable = true)\n",
            " |-- 1.4742: double (nullable = true)\n",
            " |-- 0.32396: double (nullable = true)\n",
            " |-- 0.98535: double (nullable = true)\n",
            " |-- 16: double (nullable = true)\n",
            " |-- 0.83592: double (nullable = true)\n",
            " |-- 0.0046566: double (nullable = true)\n",
            " |-- 0.0039465: double (nullable = true)\n",
            " |-- 0.04779: double (nullable = true)\n",
            " |-- 0.12795: double (nullable = true)\n",
            " |-- 0.016108: double (nullable = true)\n",
            " |-- 0.0052323: double (nullable = true)\n",
            " |-- 0.00027477: double (nullable = true)\n",
            " |-- 1.1756: double (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(10=1, 11=2, 0.72694=0.74173, 1.4742=1.5257, 0.32396=0.36116, 0.98535=0.98152, 16=0.99825, 0.83592=0.79867, 0.0046566=0.0052423, 0.0039465=0.0050016, 0.04779=0.02416, 0.12795=0.090476, 0.016108=0.0081195, 0.0052323=0.002708, 0.00027477=7.4846e-05, 1.1756=0.69659),\n",
              " Row(10=1, 11=3, 0.72694=0.76722, 1.4742=1.5725, 0.32396=0.38998, 0.98535=0.97755, 16=1.0, 0.83592=0.80812, 0.0046566=0.0074573, 0.0039465=0.010121, 0.04779=0.011897, 0.12795=0.057445, 0.016108=0.0032891, 0.0052323=0.00092068, 0.00027477=3.7886e-05, 1.1756=0.44348)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX1Fz5WzvPZy"
      },
      "source": [
        "For renaming the column names the function is created below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J5hF2F65iqq"
      },
      "source": [
        "def rename_col(s):\n",
        " mapping = {\n",
        "    '10' : 'label','11' : 'Specimen Number', '0.72694' :'Eccentricity','1.4742' :'Aspect Ratio','0.32396' : 'Elongation',\n",
        "    '0.98535' : 'Solidity', '16' : 'Stochastic Convexity','0.83592' : 'Isoperimetric Factor', '0.0046566' : 'Maximal Indentation Depth',\n",
        "    '0.0039465' : 'Lobedness', '0.04779' : 'Average Intensity', '0.12795' : 'Average Contrast', '0.016108' : 'Smoothness',\n",
        "    '0.0052323' : 'Third moment',  '0.00027477' : 'Uniformity',  '1.1756' : 'Entropy'\n",
        "      }\n",
        " return mapping[s]\n",
        "leaf = leaf.transform(quinn.with_columns_renamed(rename_col))\n",
        " "
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGcT5SpuvXGI"
      },
      "source": [
        "ın order to check null values the function is created below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6CYQUDrv9qd",
        "outputId": "6bb1b20c-f31a-422a-84c0-39d6b617ed72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def null_checker(leaf):\n",
        "  leaf.select([count(when(isnan(c), c)).alias(c) for c in leaf.columns]).show()\n",
        "  return leaf\n",
        "null_checker(leaf)"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---------------+------------+------------+----------+--------+--------------------+--------------------+-------------------------+---------+-----------------+----------------+----------+------------+----------+-------+\n",
            "|label|Specimen Number|Eccentricity|Aspect Ratio|Elongation|Solidity|Stochastic Convexity|Isoperimetric Factor|Maximal Indentation Depth|Lobedness|Average Intensity|Average Contrast|Smoothness|Third moment|Uniformity|Entropy|\n",
            "+-----+---------------+------------+------------+----------+--------+--------------------+--------------------+-------------------------+---------+-----------------+----------------+----------+------------+----------+-------+\n",
            "|    0|              0|           0|           0|         0|       0|                   0|                   0|                        0|        0|                0|               0|         0|           0|         0|      0|\n",
            "+-----+---------------+------------+------------+----------+--------+--------------------+--------------------+-------------------------+---------+-----------------+----------------+----------+------------+----------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[label: int, Specimen Number: int, Eccentricity: double, Aspect Ratio: double, Elongation: double, Solidity: double, Stochastic Convexity: double, Isoperimetric Factor: double, Maximal Indentation Depth: double, Lobedness: double, Average Intensity: double, Average Contrast: double, Smoothness: double, Third moment: double, Uniformity: double, Entropy: double]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApuDGf4WvdVf"
      },
      "source": [
        "for transforming columns the function is created below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34bYuaZs77QT",
        "outputId": "6cac6c98-c8da-4d27-a003-acb555275ca8"
      },
      "source": [
        "def transformers(leaf):\n",
        "  vec = VectorAssembler(inputCols=leaf.columns[2:],outputCol=\"features\")\n",
        "  leaf = vec.transform(leaf)\n",
        "  return leaf\n",
        "transformers(leaf)\n",
        "leaf.show(1)\n",
        "leaf =   transformers(leaf)\n"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+---------------+------------+------------+----------+--------+--------------------+--------------------+-------------------------+---------+-----------------+----------------+----------+------------+----------+-------+\n",
            "|label|Specimen Number|Eccentricity|Aspect Ratio|Elongation|Solidity|Stochastic Convexity|Isoperimetric Factor|Maximal Indentation Depth|Lobedness|Average Intensity|Average Contrast|Smoothness|Third moment|Uniformity|Entropy|\n",
            "+-----+---------------+------------+------------+----------+--------+--------------------+--------------------+-------------------------+---------+-----------------+----------------+----------+------------+----------+-------+\n",
            "|    1|              2|     0.74173|      1.5257|   0.36116| 0.98152|             0.99825|             0.79867|                0.0052423|0.0050016|          0.02416|        0.090476| 0.0081195|    0.002708| 7.4846E-5|0.69659|\n",
            "+-----+---------------+------------+------------+----------+--------+--------------------+--------------------+-------------------------+---------+-----------------+----------------+----------+------------+----------+-------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDuO_alNdhlO"
      },
      "source": [
        "One-vs-Rest classifier (a.k.a. One-vs-All)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRQxKR20cEWL"
      },
      "source": [
        "def one_vs_Rest_classifier(leaf):\n",
        "  global method\n",
        "  global maxIter\n",
        "  global tol\n",
        "  global resultseto_vs_rest\n",
        "  method = \"One-vs-Rest classifier\"\n",
        "  maxIter=10\n",
        "  tol=13-6\n",
        "  (train, test) = leaf.randomSplit([0.8, 0.2])\n",
        "\n",
        "  # instantiate the base classifier.\n",
        "  lr = LogisticRegression(maxIter=maxIter, tol=tol, fitIntercept=True)\n",
        "\n",
        "  # instantiate the One Vs Rest Classifier.\n",
        "  ovr = OneVsRest(classifier=lr)\n",
        "\n",
        "  # train the multiclass model.\n",
        "  ovrModel = ovr.fit(train)\n",
        "\n",
        "  # score the model on test data.\n",
        "  predictions = ovrModel.transform(test)\n",
        "\n",
        "  # obtain evaluator.\n",
        "  evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "\n",
        "  # compute the classification error on test data.\n",
        "  accuracy = evaluator.evaluate(predictions)\n",
        "  resultseto_vs_rest = ([{ \n",
        "    \"Method\" : method,\n",
        "    \"Parameters\" :  (\"Param1=\" + str(maxIter),\n",
        "                     \"Param2=\" + str(tol)),\n",
        "    \"Accuracy\" :  accuracy                    \n",
        "                    }])\n",
        "  return resultseto_vs_rest\n",
        "one_vs_Rest_classifier(leaf)  \n",
        "deptColumns = [\"Accuracy\",\"Method\",\"Parameters\"]\n",
        "resultseto_vs_rest = spark.createDataFrame(data=resultseto_vs_rest, schema = deptColumns)\n",
        "resultseto_vs_rest.createOrReplaceTempView(\"one_vs_rest_result\")\n",
        "result_of_onevs = spark.sql(\"select Method, Parameters, Accuracy from one_vs_rest_result\").createOrReplaceTempView(\"one_vs_rest_result\")"
      ],
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z166FpyvvKv5"
      },
      "source": [
        "Decision Tree classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etbit4jiQ_SW"
      },
      "source": [
        "def decisiontreeclassifier(leaf):\n",
        "  global resultsetdt\n",
        "  method = \"Decision Tree Classifier\"\n",
        "  trainsize = 0.7\n",
        "  testsize = 0.3\n",
        "\n",
        "\n",
        "  # Split the data into training and test sets (30% held out for testing)\n",
        "  (trainingData, testData) = leaf.randomSplit([trainsize, testsize])\n",
        "\n",
        "  # Train a DecisionTree model.\n",
        "  dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "  # Chain indexers and tree in a Pipeline\n",
        "  pipeline = Pipeline(stages=[dt])\n",
        "\n",
        "  # Train model.  This also runs the indexers.\n",
        "  model = pipeline.fit(trainingData)\n",
        "\n",
        "  # Make predictions.\n",
        "  predictions = model.transform(testData)\n",
        "\n",
        "  # Select example rows to display.\n",
        "  predictions.select(\"prediction\", \"label\", \"features\")\n",
        "\n",
        "  # Select (prediction, true label) and compute test error\n",
        "  evaluator = MulticlassClassificationEvaluator(\n",
        "      labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "  accuracy = evaluator.evaluate(predictions)\n",
        "  resultsetdt = [{ \n",
        "    \"Method\" :  method,\n",
        "    \"Parameters\" :  (\"Param1=\" + str(trainsize),\n",
        "                     \"Param2=\" + str(testsize)),\n",
        "    \"Accuracy\"  :  accuracy\n",
        "                    }]\n",
        "  return resultsetdt\n",
        "decisiontreeclassifier(leaf)\n",
        "resultsetdt\n",
        "deptColumns = [\"Accuracy\",\"Method\",\"Parameters\"]\n",
        "resultset = spark.createDataFrame(data=resultsetdt, schema = deptColumns)\n",
        "resultset.createOrReplaceTempView(\"decisiontreeresults\")\n",
        "result_of_onedt = spark.sql(\"select Method, Parameters, Accuracy from decisiontreeresults\").createOrReplaceTempView(\"decisiontreeresults\")"
      ],
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7LuvJwvlPB"
      },
      "source": [
        "random forest classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmLzBjBXJZoB"
      },
      "source": [
        "\n",
        "methodrf = \"Random Forest Classifier\"\n",
        "rfClassifier = RandomForestClassifier()\n",
        "trainDF, testDF = leaf.randomSplit([0.7,0.3],seed=123)\n",
        "eva = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "params = ParamGridBuilder()\\\n",
        "    .addGrid(rfClassifier.maxDepth, [6,7,8,9,10,11]) \\\n",
        "    .addGrid(rfClassifier.numTrees, [6,7,8,9,10,11])\\\n",
        "    .addGrid(rfClassifier.impurity, ['gini',\"entropy\"])\\\n",
        "    .build()\n",
        "\n",
        "validator = TrainValidationSplit(\n",
        "                                estimatorParamMaps=params,\n",
        "                                estimator=rfClassifier,\n",
        "                                evaluator=eva,\n",
        "                                trainRatio=0.8\n",
        "                                )\n",
        "\n",
        "\n",
        "model = validator.fit(trainDF)\n",
        "\n",
        "#print(\"Num Trees : \",model.bestModel.getNumTrees)\n",
        "#print(\"Max Depth : \",model.bestModel._java_obj.getMaxDepth())\n",
        "#print(\"Impurtiy : \",model.bestModel._java_obj.getImpurity())\n",
        "\n",
        "sonucDF = model.transform(testDF)\n",
        "\n",
        "basari = eva.evaluate(sonucDF)\n",
        "#print(\"Başarı : \",basari)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klk4pMZtOb1i"
      },
      "source": [
        "resultsetrf = ([{ \n",
        "  \"Method\" : methodrf,\n",
        "  \"Parameters\" :  (\"Param1=\" + str(model.bestModel.getNumTrees),\n",
        "                    \"Param2=\" + str(model.bestModel._java_obj.getMaxDepth())),\n",
        "  \"Accuracy\" : basari                     \n",
        "                  }])\n",
        "deptColumns = [\"Accuracy\",\"Method\",\"Parameters\"]\n",
        "resultsetrf = spark.createDataFrame(data=resultsetrf, schema = deptColumns)\n",
        "resultsetrf.createOrReplaceTempView(\"random_forest_result\")\n",
        "resultsetrf = spark.sql(\"select Method, Parameters, Accuracy from random_forest_result\").createOrReplaceTempView(\"random_forest_result\")"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r892wGBIvpag"
      },
      "source": [
        "In order to union the results of the 3 classification alghorithm the function is created below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPTiAyXaWtXO",
        "outputId": "ab8665db-fb5f-4fff-ed3d-979f90c15b85"
      },
      "source": [
        "def unioner():\n",
        " global result\n",
        " result = spark.sql(\"\"\"\n",
        "              select * from one_vs_rest_result\n",
        "                union all\n",
        "              select * from decisiontreeresults\n",
        "                union all\n",
        "              select * from random_forest_result\n",
        "              order by Accuracy desc\n",
        "              \n",
        "  \"\"\").show(truncate = False)\n",
        " return result\n",
        "unioner() "
      ],
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------+------------------------+-------------------+\n",
            "|Method                  |Parameters              |Accuracy           |\n",
            "+------------------------+------------------------+-------------------+\n",
            "|Random Forest Classifier|{Param1=7, Param2=8}    |0.6666666666666666 |\n",
            "|Decision Tree Classifier|{Param1=0.7, Param2=0.3}|0.23157894736842105|\n",
            "|One-vs-Rest classifier  |{Param1=10, Param2=7}   |0.04285714285714286|\n",
            "+------------------------+------------------------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}