{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tufan-Keser-Q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxlOq5N4FXEc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3adf618-128f-48ae-c3ff-2676a34b4371"
      },
      "source": [
        "#Apache Spark : Genel amaçlı paralel veri işleme frameworku\r\n",
        "#Hadoop üzerinde çalışabilir\r\n",
        "#Büyük Veri İşleme, Büyük Veri ile Makine Öğrenmesi ===> HADOOP + Spark\r\n",
        "!apt-get update\r\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\r\n",
        "import os\r\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\r\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\r\n",
        "!java -version\r\n",
        "!pip install pyspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,739 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,963 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,163 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,392 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [889 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,394 kB]\n",
            "Fetched 10.8 MB in 4s (3,052 kB/s)\n",
            "Reading package lists... Done\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_282\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_282-8u282-b08-0ubuntu1~18.04-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.282-b08, mixed mode)\n",
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/67/5158f846202d7f012d1c9ca21c3549a58fd3c6707ae8ee823adcaca6473c/pyspark-3.0.2.tar.gz (204.8MB)\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 74kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 21.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186687 sha256=0013a53d82ed98ac2c61a306f8c59bfe1a798377391b9409b308f389b6f72d89\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/09/da/c1f2859bcc86375dc972c5b6af4881b3603269bcc4c9be5d16\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1RewHxcqMun",
        "outputId": "e04a5779-7226-4ca2-936c-61f837f6f3c9"
      },
      "source": [
        "from geopy.distance import geodesic\r\n",
        "from geopy.point import Point\r\n",
        "from geopy.geocoders import Nominatim\r\n",
        "from operator import add\r\n",
        "from pyspark import SparkContext\r\n",
        "\r\n",
        "sc = SparkContext.getOrCreate()\r\n",
        "\r\n",
        "capitals = sc.textFile(\"Capitals.txt\")\r\n",
        "\r\n",
        "\r\n",
        "#This function is created with the purpose of splitting data\r\n",
        "def splitTake(line):\r\n",
        "    arr = line.split('\\t')\r\n",
        "    ulke=arr[1]\r\n",
        "    sehır=arr[2]\r\n",
        "    latitude=arr[3].replace(',', \".\")\r\n",
        "    longtitude =arr[4].replace(',', \".\")\r\n",
        "    arr=line.split(',')\r\n",
        "    return ulke,sehır,float(latitude),float(longtitude)\r\n",
        "\r\n",
        "capitals_correct = capitals.map(lambda line : splitTake(line)).filter(lambda x: x[2]<90 and x[2]>-90) \r\n",
        "capitals_correction = capitals.map(lambda line : splitTake(line)).filter(lambda x: x[2]>90 or x[2]<-90)\r\n",
        "#There is some of the values of latitude is miscalculated, so I prefer to divide them correct and incorrect.\r\n",
        "#By doing it, ı can take the original latitude and longtitude of them from geocoder.\r\n",
        "def loc_bul(data):\r\n",
        "  geo = Nominatim(user_agent=\"my_user_agent\")\r\n",
        "  city = data[1]\r\n",
        "  country = data[0]\r\n",
        "  loc = geo.geocode(city+','+ country)\r\n",
        "  return country,city,float(loc.latitude),float(loc.longitude)\r\n",
        "\r\n",
        "capitals_correction = capitals_correction.map(lambda line : loc_bul(line))\r\n",
        "\r\n",
        "#union correct and inccorrect data \r\n",
        "capitals_union = capitals_correct.union(capitals_correction)\r\n",
        "\r\n",
        "#cartesian join\r\n",
        "capitals_cartesian = capitals_union.cartesian(capitals_union)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def distance(data):\r\n",
        "  country_1 = data[0][0]\r\n",
        "  city_1 = data[0][1]\r\n",
        "  lat_1 = data[0][2]\r\n",
        "  lon_1 = data[0][3]\r\n",
        "  country_2 = data[1][0]\r\n",
        "  city_2 = data[1][1]\r\n",
        "  lat_2 = data[1][2]\r\n",
        "  lon_2 = data[1][3]\r\n",
        "  distance = geodesic((lat_1,lon_1),(lat_2,lon_2)).miles\r\n",
        "  return (city_1,city_2,int(distance))\r\n",
        "\r\n",
        "\r\n",
        "# After using cartesian join, there was a problem data multiplication problem. \r\n",
        "#In order to solve this problem I used .zipWithIndex() method and divide them 2.\r\n",
        "#I solved multiplication problem of cartesian join\r\n",
        "result = capitals_cartesian.map(lambda line: distance(line)).filter(lambda x: x[0] != x[1]).sortBy(lambda x: x[2],ascending=False).zipWithIndex()\r\n",
        "\r\n",
        "\r\n",
        "result = result.filter(lambda x: x[1]%2 == 0)\r\n",
        "result.take(2)\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('Abuja ', 'Nukunonu ', 12401), 0), (('Asunción ', 'Taipei ', 12388), 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}